{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e298d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1151375/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4abca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c450b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from utils.classification_utils import simple_clf\n",
    "from utils.classification_utils import  FocalBCELoss, threshold_output\n",
    "\n",
    "from upath import UPath as Path\n",
    "from torch.nn.functional import one_hot\n",
    "from ome_zarr.reader import Reader\n",
    "from ome_zarr.io import parse_url\n",
    "from aicsimageio import AICSImage, transforms\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as data\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from skimage import io\n",
    "import torchvision\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from sklearn import decomposition\n",
    "from seaborn import clustermap\n",
    "from harmony import harmonize\n",
    "from scipy.spatial.distance import squareform\n",
    "import scanpy as sc\n",
    "from scipy.sparse.linalg import eigs\n",
    "from scipy.stats import ttest_ind, zscore, norm\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import cm\n",
    "from umap import UMAP\n",
    "from random import choices\n",
    "import cuml\n",
    "\n",
    "cmap = cm.nipy_spectral\n",
    "t = torchvision.transforms.ToTensor()\n",
    "\n",
    "phases = [\n",
    "    'Interphase', \n",
    "    'prophase', \n",
    "    'early prometaphase', \n",
    "    'prometaphase/metaphase', \n",
    "    'anaphase/telophase paired',\n",
    "    'anaphase/telophase unpaired', \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5392dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f96409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sorted_trained_features, sorted_df = torch.load('WTC11_data/pretrained_features_and_df.pth')\n",
    "train_indices, test_indices = train_test_split(range(len(sorted_trained_features)), \n",
    "                                         train_size=0.8)\n",
    "train_indices = torch.load('WTC11_data/train_indices.pth')\n",
    "test_indices = torch.load('WTC11_data/test_indices.pth')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(sorted_trained_features)\n",
    "scaled_sorted_trained_features = scaler.transform(sorted_trained_features)\n",
    "scaled_sorted_trained_features = sorted_trained_features\n",
    "\n",
    "target_column = 'cell_stage'\n",
    "train_x_dino = scaled_sorted_trained_features[train_indices]\n",
    "test_x_dino = scaled_sorted_trained_features[test_indices]\n",
    "train_x_xgb = sorted_df.iloc[train_indices]\n",
    "test_x_xgb = sorted_df.iloc[test_indices]\n",
    "train_y = sorted_df[target_column].values[train_indices]\n",
    "test_y = sorted_df[target_column].values[test_indices]\n",
    "\n",
    "label2int = dict(list(zip(sorted(np.unique(train_y)), range(len(np.unique(train_y))))))\n",
    "numerical_train_y = list(map(lambda x:label2int[x], train_y))\n",
    "numerical_test_y = list(map(lambda x:label2int[x], test_y))\n",
    "\n",
    "\n",
    "from random import choices\n",
    "def balance_data(X_train, y_train):\n",
    "    k = len(y_train)\n",
    "    freq_per_class = y_train.mean(axis=0)\n",
    "    balance_freqs_per_class = 1 / (freq_per_class)\n",
    "    balance_freq_per_sample = y_train * balance_freqs_per_class\n",
    "    balance_freq_per_sample = (\n",
    "        balance_freq_per_sample.max(axis=1) / balance_freqs_per_class.max()\n",
    "    )\n",
    "    indices = choices(np.arange(k), weights=balance_freq_per_sample, k=k)\n",
    "    return (X_train[indices], y_train[indices], indices)\n",
    "from torch.nn.functional import one_hot\n",
    "one_hot_train_y = one_hot(torch.Tensor(numerical_train_y).long())\n",
    "balanced_train_x_dino, balanced_numerical_train_y, balanced_train_indices = balance_data(train_x_dino, np.array(one_hot_train_y))\n",
    "one_hot_test_y = one_hot(torch.Tensor(numerical_test_y).long())\n",
    "balanced_test_x_dino, balanced_numerical_test_y, balanced_test_indices = balance_data(test_x_dino, np.array(one_hot_test_y))\n",
    "\n",
    "classifier = simple_clf(\n",
    "    train_x_dino.shape[1],\n",
    "    one_hot_train_y.shape[1],\n",
    "    p=0.5\n",
    ")\n",
    "\n",
    "import torch.utils.data as data\n",
    "class AutoBalancedPrecomputedFeatures(data.Dataset):\n",
    "    def __init__(self, inputs, labels, balance, **kwargs):\n",
    "        self.features = inputs.detach().cpu()\n",
    "        self.labels = labels.detach().cpu()\n",
    "        self.idx = []\n",
    "        self.num_samples = len(self.features)\n",
    "        if balance:\n",
    "            self.parse_labels()\n",
    "        self.balance = balance\n",
    "\n",
    "    def parse_labels(self):\n",
    "        stats = pd.DataFrame(\n",
    "            data=[\n",
    "                {\"class\": u, \"freq\": self.labels[:, u].sum().item()}\n",
    "                for u in range(self.labels.shape[1])\n",
    "            ]\n",
    "        )\n",
    "        self.stats = stats.sort_values(by=\"freq\")\n",
    "        N = int(self.stats.freq.mean())\n",
    "        print(\"Sampling\", N, \"samples per class for\", self.labels.shape[1], \"classes\")\n",
    "        self.N = N * self.labels.shape[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        class_id = list(range(self.labels.shape[1]))[index % self.labels.shape[1]]\n",
    "        if self.balance:\n",
    "            sample_idx = np.random.choice(np.where(self.labels[:, class_id])[0], 1)\n",
    "        else:\n",
    "            sample_idx = index\n",
    "        return (\n",
    "            self.features[sample_idx],\n",
    "            self.labels[sample_idx],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "train_ds = AutoBalancedPrecomputedFeatures(torch.Tensor(train_x_dino), one_hot_train_y, balance=True)\n",
    "valid_ds = AutoBalancedPrecomputedFeatures(torch.Tensor(test_x_dino), one_hot_test_y, balance=False)\n",
    "\n",
    "\n",
    "train_sampler = torch.utils.data.RandomSampler(train_ds)\n",
    "test_sampler = torch.utils.data.SequentialSampler(valid_ds)\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=int(224),\n",
    "    sampler=train_sampler,\n",
    "    num_workers=20,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    valid_ds,\n",
    "    batch_size=int(224),\n",
    "    sampler=test_sampler,\n",
    "    num_workers=20,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR, CyclicLR, ConstantLR\n",
    "lr = 0.00005\n",
    "lr = (\n",
    "    float(lr) * (int(512) * 1) / 256.0\n",
    ")  # linear scaling rule\n",
    "\n",
    "wd = 0.04\n",
    "epochs = 100\n",
    "optim = torch.optim.AdamW(\n",
    "    classifier.parameters(),\n",
    "    lr=float(lr),\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    "    weight_decay=float(wd),\n",
    "    amsgrad=False,\n",
    ")\n",
    "total_steps = int(epochs) * len(train_dl)\n",
    "scheduler = CyclicLR(\n",
    "    optim,\n",
    "    float(lr) / 25,\n",
    "    float(lr),\n",
    "    int(total_steps / 8),\n",
    "    cycle_momentum=False,\n",
    ")\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def to_np(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return np.array(x.to(\"cpu\"))\n",
    "    return np.array(x)\n",
    "\n",
    "def get_f1_score(all_targets, all_predictions):\n",
    "    targets = to_np(torch.vstack(all_targets).detach().cpu())\n",
    "    outputs = threshold_output(\n",
    "        torch.vstack(all_predictions).detach().cpu(), use_sigmoid=True\n",
    "    )\n",
    "    score = f1_score(\n",
    "        targets.reshape(targets.shape[0], targets.shape[-1]),\n",
    "        outputs.reshape(outputs.shape[0], outputs.shape[-1]),\n",
    "        average=None,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return score    \n",
    "\n",
    "def test_model(classifier, dl, device, criterion):\n",
    "    classifier = classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions, all_targets, losses, all_features = [], [], [], []\n",
    "        batch_pbar = tqdm(\n",
    "            enumerate(dl),\n",
    "            total=len(dl),\n",
    "            unit=\" test batches\",\n",
    "            position=1,\n",
    "            leave=False,\n",
    "        )\n",
    "        for index, (images, targets) in batch_pbar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            features = images\n",
    "            outputs = classifier(features)\n",
    "            loss = criterion(\n",
    "                outputs.reshape(targets.shape[0], 1, targets.shape[-1]),\n",
    "                targets.float().reshape(targets.shape[0], 1, targets.shape[-1]),\n",
    "            )\n",
    "            losses.append(loss.item())\n",
    "            predictions.extend(outputs)\n",
    "            # all_features.extend(features)\n",
    "            all_targets.extend(targets)\n",
    "    score = get_f1_score(all_targets, predictions)\n",
    "    batch_pbar.close()\n",
    "    classifier = classifier.train()\n",
    "    return np.mean(losses), score, all_targets, predictions\n",
    "\n",
    "import math\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "classifier.to(device)\n",
    "epochs_to_run = epochs\n",
    "epoch_pbar = tqdm(\n",
    "    range(epochs_to_run),\n",
    "    total=epochs_to_run,\n",
    "    unit=\" epochs\",\n",
    "    position=0,\n",
    "    leave=True,\n",
    ")\n",
    "test_scores = []\n",
    "for epoch in epoch_pbar:\n",
    "    classifier = classifier.train()\n",
    "    train_predictions, train_targets, train_loss = [], [], []\n",
    "    batch_pbar = tqdm(\n",
    "        enumerate(train_dl),\n",
    "        total=len(train_dl),\n",
    "        unit=\" batches\",\n",
    "        position=1,\n",
    "        leave=False,\n",
    "    )\n",
    "    for index, (images, targets) in batch_pbar:\n",
    "        iteration = len(train_dl) * epoch + index  # global training iteration\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        features = images\n",
    "\n",
    "        outputs = classifier(features)\n",
    "        loss = criterion(\n",
    "            outputs, targets.float().reshape(targets.shape[0], 1, targets.shape[-1])\n",
    "        )\n",
    "\n",
    "        if not math.isfinite(loss.item()):\n",
    "            print(\"Loss is {}, stopping training\".format(loss.item()), force=True)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "    test_scores.append(np.mean(test_model(classifier, test_dl, device, criterion)[1]))\n",
    "    print(test_scores[-1])\n",
    "\n",
    "plt.plot(test_scores)\n",
    "train_loss, train_score,all_targets, predictions  = test_model(classifier, train_dl, device, criterion)\n",
    "test_loss, test_score,all_targets, predictions = test_model(classifier, test_dl, device, criterion)\n",
    "print(f'Average test score: {np.mean(test_score)}')\n",
    "print(f'Test score: {(test_score)}')\n",
    "print(f'Train score: {np.mean(train_score)}')    \n",
    "\n",
    "try:\n",
    "    all_targets = torch.stack(all_targets)\n",
    "except:\n",
    "    pass\n",
    "all_targets = all_targets.detach().cpu()\n",
    "\n",
    "try:\n",
    "    predictions = torch.stack(predictions)\n",
    "except:\n",
    "    pass\n",
    "predictions = predictions.detach().cpu()\n",
    "torch.save((all_targets, predictions), 'pretrained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9b6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798cee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sorted_trained_features, sorted_df = torch.load('WTC11_data/DINO_features_and_df.pth')\n",
    "train_indices, test_indices = train_test_split(range(len(sorted_trained_features)), \n",
    "                                         train_size=0.8)\n",
    "train_indices = torch.load('WTC11_data/train_indices.pth')\n",
    "test_indices = torch.load('WTC11_data/test_indices.pth')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(sorted_trained_features)\n",
    "scaled_sorted_trained_features = scaler.transform(sorted_trained_features)\n",
    "scaled_sorted_trained_features = sorted_trained_features\n",
    "\n",
    "# target_column = 'Protein'\n",
    "target_column = 'cell_stage'\n",
    "train_x_dino = scaled_sorted_trained_features[train_indices]\n",
    "test_x_dino = scaled_sorted_trained_features[test_indices]\n",
    "train_x_xgb = sorted_df.iloc[train_indices]\n",
    "test_x_xgb = sorted_df.iloc[test_indices]\n",
    "train_y = sorted_df[target_column].values[train_indices]\n",
    "test_y = sorted_df[target_column].values[test_indices]\n",
    "# train_y = sorted_df.cell_stage.values[train_indices]\n",
    "# test_y = sorted_df.cell_stage.values[test_indices]\n",
    "\n",
    "label2int = dict(list(zip(sorted(np.unique(train_y)), range(len(np.unique(train_y))))))\n",
    "numerical_train_y = list(map(lambda x:label2int[x], train_y))\n",
    "numerical_test_y = list(map(lambda x:label2int[x], test_y))\n",
    "\n",
    "\n",
    "from random import choices\n",
    "def balance_data(X_train, y_train):\n",
    "    k = len(y_train)\n",
    "    freq_per_class = y_train.mean(axis=0)\n",
    "    balance_freqs_per_class = 1 / (freq_per_class)\n",
    "    balance_freq_per_sample = y_train * balance_freqs_per_class\n",
    "    balance_freq_per_sample = (\n",
    "        balance_freq_per_sample.max(axis=1) / balance_freqs_per_class.max()\n",
    "    )\n",
    "    indices = choices(np.arange(k), weights=balance_freq_per_sample, k=k)\n",
    "    return (X_train[indices], y_train[indices], indices)\n",
    "from torch.nn.functional import one_hot\n",
    "one_hot_train_y = one_hot(torch.Tensor(numerical_train_y).long())\n",
    "balanced_train_x_dino, balanced_numerical_train_y, balanced_train_indices = balance_data(train_x_dino, np.array(one_hot_train_y))\n",
    "one_hot_test_y = one_hot(torch.Tensor(numerical_test_y).long())\n",
    "balanced_test_x_dino, balanced_numerical_test_y, balanced_test_indices = balance_data(test_x_dino, np.array(one_hot_test_y))\n",
    "\n",
    "\n",
    "classifier = simple_clf(\n",
    "    train_x_dino.shape[1],\n",
    "    one_hot_train_y.shape[1],\n",
    "    p=0.5\n",
    ")\n",
    "\n",
    "import torch.utils.data as data\n",
    "class AutoBalancedPrecomputedFeatures(data.Dataset):\n",
    "    def __init__(self, inputs, labels, balance, **kwargs):\n",
    "        self.features = inputs.detach().cpu()\n",
    "        self.labels = labels.detach().cpu()\n",
    "        self.idx = []\n",
    "        self.num_samples = len(self.features)\n",
    "        if balance:\n",
    "            self.parse_labels()\n",
    "        self.balance = balance\n",
    "\n",
    "    def parse_labels(self):\n",
    "        stats = pd.DataFrame(\n",
    "            data=[\n",
    "                {\"class\": u, \"freq\": self.labels[:, u].sum().item()}\n",
    "                for u in range(self.labels.shape[1])\n",
    "            ]\n",
    "        )\n",
    "        self.stats = stats.sort_values(by=\"freq\")\n",
    "        N = int(self.stats.freq.mean())\n",
    "        print(\"Sampling\", N, \"samples per class for\", self.labels.shape[1], \"classes\")\n",
    "        self.N = N * self.labels.shape[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        class_id = list(range(self.labels.shape[1]))[index % self.labels.shape[1]]\n",
    "        if self.balance:\n",
    "            sample_idx = np.random.choice(np.where(self.labels[:, class_id])[0], 1)\n",
    "        else:\n",
    "            sample_idx = index\n",
    "        return (\n",
    "            self.features[sample_idx],\n",
    "            self.labels[sample_idx],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "train_ds = AutoBalancedPrecomputedFeatures(torch.Tensor(train_x_dino), one_hot_train_y, balance=True)\n",
    "valid_ds = AutoBalancedPrecomputedFeatures(torch.Tensor(test_x_dino), one_hot_test_y, balance=False)\n",
    "\n",
    "\n",
    "train_sampler = torch.utils.data.RandomSampler(train_ds)\n",
    "test_sampler = torch.utils.data.SequentialSampler(valid_ds)\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=int(224),\n",
    "    sampler=train_sampler,\n",
    "    num_workers=10,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    valid_ds,\n",
    "    batch_size=int(224),\n",
    "    sampler=test_sampler,\n",
    "    num_workers=10,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR, CyclicLR, ConstantLR\n",
    "lr = 0.00005\n",
    "lr = (\n",
    "    float(lr) * (int(512) * 1) / 256.0\n",
    ")  # linear scaling rule\n",
    "\n",
    "wd = 0.04\n",
    "epochs = 100\n",
    "optim = torch.optim.AdamW(\n",
    "    classifier.parameters(),\n",
    "    lr=float(lr),\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    "    weight_decay=float(wd),\n",
    "    amsgrad=False,\n",
    ")\n",
    "total_steps = int(epochs) * len(train_dl)\n",
    "scheduler = CyclicLR(\n",
    "    optim,\n",
    "    float(lr) / 25,\n",
    "    float(lr),\n",
    "    int(total_steps / 8),\n",
    "    cycle_momentum=False,\n",
    ")\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def to_np(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return np.array(x.to(\"cpu\"))\n",
    "    return np.array(x)\n",
    "\n",
    "def get_f1_score(all_targets, all_predictions):\n",
    "    targets = to_np(torch.vstack(all_targets).detach().cpu())\n",
    "    outputs = threshold_output(\n",
    "        torch.vstack(all_predictions).detach().cpu(), use_sigmoid=True\n",
    "    )\n",
    "    score = f1_score(\n",
    "        targets.reshape(targets.shape[0], targets.shape[-1]),\n",
    "        outputs.reshape(outputs.shape[0], outputs.shape[-1]),\n",
    "        average=None,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    return score    \n",
    "\n",
    "def test_model(classifier, dl, device, criterion):\n",
    "    classifier = classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions, all_targets, losses, all_features = [], [], [], []\n",
    "        batch_pbar = tqdm(\n",
    "            enumerate(dl),\n",
    "            total=len(dl),\n",
    "            unit=\" test batches\",\n",
    "            position=1,\n",
    "            leave=False,\n",
    "        )\n",
    "        for index, (images, targets) in batch_pbar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            features = images\n",
    "            outputs = classifier(features)\n",
    "            loss = criterion(\n",
    "                outputs.reshape(targets.shape[0], 1, targets.shape[-1]),\n",
    "                targets.float().reshape(targets.shape[0], 1, targets.shape[-1]),\n",
    "            )\n",
    "            losses.append(loss.item())\n",
    "            predictions.extend(outputs)\n",
    "            # all_features.extend(features)\n",
    "            all_targets.extend(targets)\n",
    "    score = get_f1_score(all_targets, predictions)\n",
    "    batch_pbar.close()\n",
    "    classifier = classifier.train()\n",
    "    return np.mean(losses), score, all_targets, predictions\n",
    "\n",
    "import math\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "classifier.to(device)\n",
    "epochs_to_run = epochs\n",
    "epoch_pbar = tqdm(\n",
    "    range(epochs_to_run),\n",
    "    total=epochs_to_run,\n",
    "    unit=\" epochs\",\n",
    "    position=0,\n",
    "    leave=True,\n",
    ")\n",
    "test_scores = []\n",
    "for epoch in epoch_pbar:\n",
    "    classifier = classifier.train()\n",
    "    train_predictions, train_targets, train_loss = [], [], []\n",
    "    batch_pbar = tqdm(\n",
    "        enumerate(train_dl),\n",
    "        total=len(train_dl),\n",
    "        unit=\" batches\",\n",
    "        position=1,\n",
    "        leave=False,\n",
    "    )\n",
    "    for index, (images, targets) in batch_pbar:\n",
    "        iteration = len(train_dl) * epoch + index  # global training iteration\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        features = images\n",
    "\n",
    "        outputs = classifier(features)\n",
    "        loss = criterion(\n",
    "            outputs, targets.float().reshape(targets.shape[0], 1, targets.shape[-1])\n",
    "        )\n",
    "\n",
    "        if not math.isfinite(loss.item()):\n",
    "            print(\"Loss is {}, stopping training\".format(loss.item()), force=True)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "    test_scores.append(np.mean(test_model(classifier, test_dl, device, criterion)[1]))\n",
    "    print(test_scores[-1])\n",
    "\n",
    "plt.plot(test_scores)\n",
    "train_loss, train_score,all_targets, predictions  = test_model(classifier, train_dl, device, criterion)\n",
    "test_loss, test_score,all_targets, predictions = test_model(classifier, test_dl, device, criterion)\n",
    "print(f'Average test score: {np.mean(test_score)}')\n",
    "print(f'Test score: {(test_score)}')\n",
    "print(f'Train score: {np.mean(train_score)}')    \n",
    "\n",
    "try:\n",
    "    all_targets = torch.stack(all_targets)\n",
    "except:\n",
    "    pass\n",
    "all_targets = all_targets.detach().cpu()\n",
    "\n",
    "try:\n",
    "    predictions = torch.stack(predictions)\n",
    "except:\n",
    "    pass\n",
    "predictions = predictions.detach().cpu()\n",
    "torch.save((all_targets, predictions), 'trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47d70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5160e8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a23c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286cc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = pd.read_csv('WTC11_data/normalized_cell_df.csv')\n",
    "xgb_feature_df = sorted_df[['angle', 'bbox_max_x', 'bbox_max_y', 'bbox_max_z',\n",
    "       'bbox_min_x', 'bbox_min_y', 'bbox_min_z', 'bf_clip_hi', 'bf_clip_lo',\n",
    "       'cell_height', 'cell_surface_area', 'cell_volume',\n",
    "        'dna_clip_hi', 'dna_clip_lo', 'membrane_clip_hi', 'membrane_clip_lo', \n",
    "        'nuclear_height', 'nuclear_surface_area',\n",
    "       'nuclear_volume', 'shape_mode_1_height', 'shape_mode_2_volume',\n",
    "       'shape_mode_3_major_tilt', 'shape_mode_4_minor_tilt',\n",
    "       'shape_mode_5_elongation', 'shape_mode_6_bean-ness',\n",
    "       'shape_mode_7_pear-ness', 'shape_mode_8_wedge', 'meta_colony_centroid_1', 'meta_colony_centroid_2']]\n",
    "engineered_values = xgb_feature_df.values\n",
    "engineered_values, values = torch.load('WTC11_data/engineered_features.pth')\n",
    "\n",
    "target_column = 'Protein'\n",
    "target_column = 'cell_stage'\n",
    "\n",
    "train_indices = torch.load('WTC11_data/train_indices.pth')\n",
    "test_indices = torch.load('WTC11_data/test_indices.pth')\n",
    "\n",
    "train_x_xgb = engineered_values[train_indices]\n",
    "test_x_xgb = engineered_values[test_indices]\n",
    "train_y = sorted_df[target_column].values[train_indices]\n",
    "test_y = sorted_df[target_column].values[test_indices]\n",
    "label2int = dict(list(zip(sorted(np.unique(train_y)), range(len(np.unique(train_y))))))\n",
    "numerical_train_y = list(map(lambda x:label2int[x], train_y))\n",
    "numerical_test_y = list(map(lambda x:label2int[x], test_y))\n",
    "one_hot_train_y = one_hot(torch.Tensor(numerical_train_y).long())\n",
    "one_hot_test_y = one_hot(torch.Tensor(numerical_test_y).long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef6757",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_y = one_hot(torch.Tensor(numerical_train_y).long())\n",
    "balanced_train_x_xgboost, balanced_numerical_train_y, balanced_train_indices = balance_data(train_x_xgb, np.array(one_hot_train_y))\n",
    "one_hot_test_y = one_hot(torch.Tensor(numerical_test_y).long())\n",
    "balanced_test_x_xgboost, balanced_numerical_test_y, balanced_test_indices = balance_data(test_x_xgb, np.array(one_hot_test_y))\n",
    "balanced_numerical_train_y = np.array(numerical_train_y)[balanced_train_indices]\n",
    "balanced_numerical_test_y = np.array(numerical_test_y)[balanced_test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35064957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = XGBClassifier()\n",
    "model.fit(balanced_train_x_xgboost, np.array(balanced_numerical_train_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59587a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x_xgb)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "xgbscores = f1_score(numerical_test_y, predictions, average=None)\n",
    "print(xgbscores)\n",
    "print(np.mean(xgbscores))\n",
    "torch.save((numerical_test_y, predictions), 'xgb_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
