{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da042e97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1009748/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e5dd36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from sklearn import decomposition\n",
    "from harmony import harmonize\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "import utils.label_dict\n",
    "from utils.label_dict import protein_to_num_single_cells\n",
    "from utils.analysis_utils import plot_UMAP, get_embeddings, create_cell_comparison, create_protein_hierarchy, get_gene_heterogeneity_enrichement, plot_gene_heterogeneity_enrichement, get_heterogeneity_df, scale, get_heterogeneousity_per_whole_image, get_col_matrix\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from seaborn import clustermap\n",
    "from skimage import io\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import scanpy as sc\n",
    "from scipy.sparse.linalg import eigs\n",
    "from scipy.stats import ttest_ind, zscore, norm\n",
    "\n",
    "cmap = cm.nipy_spectral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52f1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduced_features(features, n_components=100):\n",
    "    pca = decomposition.PCA(n_components=n_components)\n",
    "    pca = pca.fit(features)\n",
    "    print(sum(pca.explained_variance_ratio_))\n",
    "    return pca.transform(features)\n",
    "\n",
    "\n",
    "def get_harmonized_features(features, df, key):\n",
    "    return harmonize(torch.Tensor(features).numpy(), \n",
    "                                    df,\n",
    "                                    batch_key = key, \n",
    "                                    use_gpu=True,\n",
    "                                    random_state=42,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def get_averaged_features(df, features, labels, sort=True):\n",
    "    mat, columns = get_col_matrix(df, labels)\n",
    "    averaged_features = []\n",
    "    for key in range(len(columns)):\n",
    "        indices = np.where((mat[:,key] == 1) & (mat.sum(axis=1) == 1))\n",
    "        averaged_features.append(features[indices].mean(axis=0))\n",
    "    averaged_features = torch.stack(averaged_features)\n",
    "    return averaged_features, columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75509e",
   "metadata": {},
   "source": [
    "### Create UMAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a72a31df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a27ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = ['Interphase', \n",
    "'prophase', \n",
    "'early prometaphase', \n",
    "'prometaphase/metaphase', \n",
    "'anaphase/telophase paired',\n",
    "'anaphase/telophase unpaired', \n",
    "]\n",
    "\n",
    "sorted_trained_features, sorted_df  = torch.load('WTC11_data/DINO_features_and_df.pth')\n",
    "cleaned_sorted_trained_embedding = torch.load('WTC11_data/Allen_3_channel_trained_embedding.pth')\n",
    "cleaned_sorted_trained_harmonized_features = torch.load('WTC11_data/Allen_3_channel_trained_embedding_harmonized.pth')\n",
    "\n",
    "embedding = cleaned_sorted_trained_embedding\n",
    "\n",
    "structure_mat, structure_labels = get_col_matrix(sorted_df, ['Structure'])\n",
    "stage_mat, stage_labels = get_col_matrix(sorted_df, ['cell_stage'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10), facecolor='white', dpi=300)\n",
    "for cell_ind in range(structure_mat.shape[1]):\n",
    "    cell_indices = np.where(structure_mat[:,cell_ind])\n",
    "    plt.scatter(embedding[cell_indices, 0],\n",
    "                embedding[cell_indices, 1],\n",
    "                s = 0.01,\n",
    "                color=cmap(cell_ind / structure_mat.shape[1]),\n",
    "                label=structure_labels[cell_ind]\n",
    "               )\n",
    "plt.axis('off') \n",
    "plt.savefig('results/WTC11/WTC11_structure_umap.pdf', format='pdf')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10), facecolor='white', dpi=300)\n",
    "plt.scatter(embedding[:, 0],\n",
    "            embedding[:, 1],\n",
    "            s = 0.01,\n",
    "            color='grey'\n",
    "           )\n",
    "for stage_ind in range(stage_mat.shape[1]):\n",
    "    stage_indices = np.where(stage_mat[:,stage_ind])\n",
    "    plt.scatter(embedding[stage_indices, 0],\n",
    "                embedding[stage_indices, 1],\n",
    "                s = 0.01,\n",
    "                color=cmap(stage_ind / stage_mat.shape[1]),\n",
    "                label=phases[stage_ind]\n",
    "               )\n",
    "plt.axis('off')\n",
    "plt.savefig('results/WTC11/WTC11_stage_umap.pdf', format='pdf')\n",
    "\n",
    "\n",
    "embedding = cleaned_sorted_trained_harmonized_features\n",
    "\n",
    "structure_mat, structure_labels = get_col_matrix(sorted_df, ['Structure'])\n",
    "stage_mat, stage_labels = get_col_matrix(sorted_df, ['cell_stage'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10), facecolor='white', dpi=300)\n",
    "for cell_ind in range(structure_mat.shape[1]):\n",
    "    cell_indices = np.where(structure_mat[:,cell_ind])\n",
    "    plt.scatter(embedding[cell_indices, 0],\n",
    "                embedding[cell_indices, 1],\n",
    "                s = 0.01,\n",
    "                color=cmap(cell_ind / structure_mat.shape[1])\n",
    "               )\n",
    "plt.axis('off')\n",
    "plt.savefig('results/WTC11/harmonized_WTC11_structure_umap.pdf', format='pdf')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10), facecolor='white', dpi=300)\n",
    "plt.scatter(embedding[:, 0],\n",
    "            embedding[:, 1],\n",
    "            s = 0.01,\n",
    "            color='grey'\n",
    "           )\n",
    "for stage_ind in range(stage_mat.shape[1]):\n",
    "    stage_indices = np.where(stage_mat[:,stage_ind])\n",
    "    plt.scatter(embedding[stage_indices, 0],\n",
    "                embedding[stage_indices, 1],\n",
    "                s = 0.01,\n",
    "                color=cmap(stage_ind / stage_mat.shape[1])\n",
    "               )\n",
    "plt.axis('off')\n",
    "plt.savefig('results/WTC11/harmonized_WTC11_stage_umap.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f554dcb4",
   "metadata": {},
   "source": [
    "### Plot mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d43c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def create_bins(x):\n",
    "    unique_xs = sorted(np.unique(x))\n",
    "    bins = [unique_xs[0] - 0.5]\n",
    "    for ind in range(len(unique_xs) - 1):\n",
    "        bins.append(unique_xs[ind] + (unique_xs[ind + 1] - unique_xs[ind]) / 2)\n",
    "    bins = bins + [unique_xs[-1] + 0.5]  \n",
    "    return bins\n",
    "\n",
    "def mutual_info(x,y,code_bin, factor_bin):\n",
    "    c_xy = np.histogram2d(x,y,(code_bin, factor_bin))[0]\n",
    "    mi = 0\n",
    "    N = np.sum(c_xy)\n",
    "    for i in range(c_xy.shape[0]):\n",
    "        for j in range(c_xy.shape[1]):\n",
    "            p_i = np.sum(c_xy[i,:]) / N\n",
    "            p_j = np.sum(c_xy[:,j]) / N\n",
    "            p_ij = c_xy[i,j] / N\n",
    "            if p_ij == 0: \n",
    "                mi += 0 \n",
    "            else:\n",
    "                mi += (p_ij) * np.log(p_ij / (p_i * p_j))\n",
    "    return mi\n",
    "\n",
    "def conditional_mutual_info(x,y,z,bins):\n",
    "    c_xyz = np.histogramdd((x, \n",
    "                          y, \n",
    "                          z),\n",
    "                          bins)[0]\n",
    "    N = np.sum(c_xyz)\n",
    "    mi = 0\n",
    "    p_z = c_xyz.sum(axis=(0,1)) / N\n",
    "    p_iz = c_xyz.sum(axis=(1)) / N\n",
    "    p_jz = c_xyz.sum(axis=(0)) / N\n",
    "    p_ijzs = c_xyz / N\n",
    "    N = np.sum(c_xyz)\n",
    "    for i in (range(c_xyz.shape[0])):\n",
    "        for j in range(c_xyz.shape[1]):\n",
    "            for z in range(c_xyz.shape[2]):\n",
    "                if p_ijzs[i,j,z] == 0: \n",
    "                    mi += 0 \n",
    "                else:\n",
    "                    mi += (p_ijzs[i,j,z]) * np.log((p_z[z] * p_ijzs[i,j,z]) / (p_iz[i,z] * p_jz[j,z]))\n",
    "    return mi    \n",
    "\n",
    "\n",
    "def MI(x, y, bins):\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
    "    return mi\n",
    "\n",
    "def get_col_matrix(df, labels):\n",
    "    if len(labels) == 1:\n",
    "        values = df[labels[0]]\n",
    "        unique_values = sorted(np.unique(values))\n",
    "        mat = np.zeros((len(df), len(unique_values)))\n",
    "        for ind, value in enumerate(unique_values):\n",
    "            mat[np.where(values == value)[0], ind] = 1\n",
    "        columns = unique_values\n",
    "    else:\n",
    "        mat = df[sorted(labels)].values.astype(int)\n",
    "        columns = sorted(labels)\n",
    "    return mat, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e0966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5769f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fd52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b76a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372db0ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m code_bin, factor_bin \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(code_bins, factor_bins):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature_file, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(feature_files, labels):\n\u001b[0;32m---> 21\u001b[0m         config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(\u001b[38;5;28mopen\u001b[39m(\u001b[43mconfig_file\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m             features, _, IDs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_path\u001b[39m\u001b[38;5;124m'\u001b[39m])            \n",
      "\u001b[0;31mNameError\u001b[0m: name 'config_file' is not defined"
     ]
    }
   ],
   "source": [
    "feature_files = [\n",
    "    'WTC11_data/DINO_features_and_df.pth',\n",
    "    'WTC11_data/DINO_features_and_df.pth',\n",
    "    'WTC11_data/engineered_features.pth'\n",
    "]\n",
    "labels = [\n",
    "    'Trained DINO',\n",
    "    'Trained DINO,\\nharmonized',\n",
    "    'Engineered features',\n",
    "             ]\n",
    "allen_model_labels = labels\n",
    "allen_factor_labels = ['Protein structure', 'Cell stage', 'Well']\n",
    "df = pd.read_csv('WTC11_data/normalized_cell_df.csv')\n",
    "factor_gaps_per_method = []\n",
    "allen_mi_matrices = []\n",
    "allen_model_labels = labels\n",
    "code_bins = [6]\n",
    "factor_bins = [6]\n",
    "for code_bin, factor_bin in zip(code_bins, factor_bins):\n",
    "    for feature_file, label in zip(feature_files, labels):\n",
    "        try:\n",
    "            features, _, df = torch.load(feature_files)            \n",
    "        except:\n",
    "            features, df = torch.load(feature_files)            \n",
    "        reduced_features = features\n",
    "    \n",
    "        if 'harmonized' in label:\n",
    "            reduced_features = harmonize(torch.Tensor(reduced_features).numpy(), \n",
    "                                            df,\n",
    "                                            batch_key = ['Structure'], \n",
    "                                            use_gpu=True,\n",
    "                                            random_state=42,\n",
    "            )        \n",
    "            \n",
    "\n",
    "        well_mat, well_labels = get_col_matrix(df, ['WellId'])    \n",
    "        structure_mat, structure_labels = get_col_matrix(df, ['Structure'])    \n",
    "        stage_mat, stage_labels = get_col_matrix(df, ['cell_stage'])    \n",
    "        factors = np.stack((np.argmax(structure_mat, axis=1),\n",
    "                        np.argmax(stage_mat, axis=1),\n",
    "                        np.argmax(well_mat, axis=1))).T\n",
    "        codes = torch.Tensor(reduced_features)\n",
    "\n",
    "        allen_protein_MI = []\n",
    "        allen_cell_MI = []\n",
    "        allen_well_MI = []\n",
    "\n",
    "        for i in tqdm(range(codes.shape[1])):\n",
    "            protein_mi = mutual_info(codes[:,i].numpy(), factors[:,0], code_bin, factor_bin)\n",
    "            allen_protein_MI.append(protein_mi)\n",
    "            cell_mi = mutual_info(codes[:,i].numpy(), factors[:,1], code_bin, factor_bin)\n",
    "            allen_cell_MI.append(cell_mi)    \n",
    "            well_mi = mutual_info(codes[:,i].numpy(), factors[:,2], code_bin, factor_bin)\n",
    "            allen_well_MI.append(well_mi)      \n",
    "        mi_matrix = np.stack((allen_protein_MI, allen_cell_MI, allen_well_MI))\n",
    "    #     dcimig_score, mi_matrix = dcimig(factors, codes)\n",
    "        highest_factor_mask = np.array(list(zip(np.argsort(mi_matrix, axis=0)[::-1][0,:], range(mi_matrix.shape[1])))).T\n",
    "        second_highest_factor_mask = np.array(list(zip(np.argsort(mi_matrix, axis=0)[::-1][1,:], range(mi_matrix.shape[1])))).T\n",
    "        gap = mi_matrix[highest_factor_mask[0,:],:].diagonal() - mi_matrix[second_highest_factor_mask[0,:],:].diagonal()\n",
    "        factor_indices = [np.where(mi_matrix[i,:] >= np.max(mi_matrix, axis=0))[0] for i in range(factors.shape[1])]\n",
    "        factor_gaps = [gap[f].max() if len(f) > 0 else 0 for f in factor_indices]\n",
    "        factor_gaps_per_method.append(factor_gaps)\n",
    "        allen_mi_matrices.append(mi_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e503e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.stats import pearsonr\n",
    "cmap = cm.nipy_spectral\n",
    "\n",
    "dominant_fov_percentages = []\n",
    "for matrix_ind, (mi_matrix, mi_label) in enumerate(zip(allen_mi_matrices, allen_model_labels)):\n",
    "    whole_HPA_protein_MI = mi_matrix[0,:]\n",
    "    whole_HPA_cell_MI = mi_matrix[1,:]\n",
    "    whole_HPA_well_MI = mi_matrix[2,:]\n",
    "    high_protein = np.where((whole_HPA_protein_MI > whole_HPA_cell_MI) & (whole_HPA_protein_MI > whole_HPA_well_MI))[0]\n",
    "    high_protein = high_protein[np.argsort(whole_HPA_protein_MI[high_protein])][::-1]\n",
    "    high_cell = np.where((whole_HPA_cell_MI > whole_HPA_protein_MI) & (whole_HPA_cell_MI > whole_HPA_well_MI))[0]\n",
    "    high_cell = high_cell[np.argsort(whole_HPA_cell_MI[high_cell])][::-1]\n",
    "    high_well = np.where((whole_HPA_well_MI > whole_HPA_protein_MI) & (whole_HPA_well_MI > whole_HPA_cell_MI))[0]\n",
    "    high_well = high_well[np.argsort(whole_HPA_well_MI[high_well])][::-1]\n",
    "    new_indices = np.concatenate((high_protein, high_cell, high_well))\n",
    "    dominant_fov_percentage = [len(high_protein) / len(new_indices),\n",
    "                               len(high_cell) / len(new_indices),\n",
    "                               len(high_well) / len(new_indices),]\n",
    "    dominant_fov_percentages.append(dominant_fov_percentage)\n",
    "                               \n",
    "dominant_fov_percentages = np.array(dominant_fov_percentages) * 100\n",
    "dominant_fov_percentages = dominant_fov_percentages[:,np.argsort(dominant_fov_percentages[0,:])[::-1]]\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib\n",
    "font = {'size'   : 7}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(2.5,2.5), dpi=300)\n",
    "\n",
    "plt.bar(\n",
    "    range(len(dominant_fov_percentages)),\n",
    "    bottom = 0,\n",
    "    height = dominant_fov_percentages[:,0],\n",
    "    label='Wells',\n",
    "       )\n",
    "plt.bar(\n",
    "    range(len(dominant_fov_percentages)),\n",
    "    bottom = dominant_fov_percentages[:,:1].sum(axis=1),\n",
    "    height = dominant_fov_percentages[:,1],\n",
    "    label='Cell line',\n",
    "       )\n",
    "plt.bar(\n",
    "    range(len(dominant_fov_percentages)),\n",
    "    bottom = dominant_fov_percentages[:,:2].sum(axis=1),\n",
    "    height = dominant_fov_percentages[:,2],\n",
    "    label='Protein'\n",
    "       )\n",
    "plt.legend(bbox_to_anchor=(1.75,0.5), loc='center right', frameon=False)\n",
    "plt.ylabel('% encoding features')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.xticks(range(len(allen_model_labels)),allen_model_labels, rotation=90)\n",
    "\n",
    "plt.savefig('results/WTC11/WTC11_mutual_information.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6742aaa",
   "metadata": {},
   "source": [
    "### Plot classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc57c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131338bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DINO_train = 0.823\n",
    "DINO_pretrained = 0.89\n",
    "XGBoost = 0.751 \n",
    "\n",
    "fig, axis = plt.subplots(1,1,figsize=(2.5,2.5), dpi=300)\n",
    "plt.bar(x=[0], height=[XGBoost], color='#35c073')\n",
    "plt.bar(x=[1], height=[DINO_pretrained], color='#d72827')\n",
    "plt.bar(x=[2], height=[DINO_train], color='#3993dd')\n",
    "plt.ylabel('Average accuracy')\n",
    "plt.xticks([])\n",
    "plt.axis([-0.5, 2.5, 0, 1])\n",
    "plt.savefig('results/WTC11/WTC11_Cell_Cycle.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['predictions_for_WTC11_xgb','predictions_for_WTC11_trained_model','predictions_for_WTC11_pretrained_model']:\n",
    "    all_targets, predictions, = torch.load(f'WTC11_data/{model_name}.pth')\n",
    "    try:\n",
    "        mat = confusion_matrix(predictions, all_targets, normalize='true')\n",
    "    except:\n",
    "        mat = confusion_matrix(np.argmax(predictions, axis=1), np.argmax(all_targets, axis=1), normalize='true')\n",
    "    rounded_mat = np.copy(mat)\n",
    "    rounded_mat[np.where(rounded_mat < 0.01)[0], \n",
    "                np.where(rounded_mat < 0.01)[1]] = 0\n",
    "    fig = plt.figure(figsize=(1,1), dpi=300)\n",
    "    c = ConfusionMatrixDisplay(confusion_matrix=rounded_mat, display_labels=phases)\n",
    "    c.plot(cmap='Reds', text_kw={'fontsize' : 17}, values_format='.1g', colorbar=False)\n",
    "    axes = c.ax_\n",
    "    axes.set_yticks([])\n",
    "    axes.set_yticks([])\n",
    "    axes.set_yticklabels([])\n",
    "    axes.set_xticks([])\n",
    "    axes.set_xlabel('')\n",
    "    axes.set_ylabel('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4cf6ed",
   "metadata": {},
   "source": [
    "### Pseudotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328cb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = pd.read_csv('WTC11_data/normalized_cell_df.csv')\n",
    "features_g = torch.load('WTC11_data/pretrained_g_features.pth')\n",
    "features_b = torch.load('WTC11_data/pretrained_b_features.pth')\n",
    "features_y = torch.load('WTC11_data/pretrained_y_features.pth')\n",
    "sorted_trained_features = torch.concat([\n",
    "             features_g[0],\n",
    "             features_b[0],\n",
    "             features_y[0],\n",
    "                 ], axis=1)\n",
    "sorted_trained_features[np.unique(np.where(np.isnan(sorted_trained_features.numpy()))[0])] = 0   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3500c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 50\n",
    "samples_per_cell_stage = 1000\n",
    "sorted_df['cell_stage'] = sorted_df['cell_stage'].map(dict(zip(sorted(sorted_df['cell_stage'].unique()), phases)))\n",
    "\n",
    "cell_stage_groups = sorted_df.reset_index().groupby(['cell_stage']).groups\n",
    "balanced_indices = np.concatenate([(cell_stage_groups[key][:samples_per_cell_stage]) for key in cell_stage_groups])\n",
    "reduced_features = get_reduced_features(sorted_trained_features[balanced_indices], n_components=n_components)\n",
    "sorted_df =  sorted_df.iloc[balanced_indices].reset_index()\n",
    "harmonized_features = get_harmonized_features(reduced_features, sorted_df, ['Structure'])\n",
    "\n",
    "features_to_analyse = torch.Tensor(harmonized_features).numpy()\n",
    "adata = sc.AnnData(features_to_analyse, obs=sorted_df[['CellId','Structure','cell_stage']], \n",
    "                   var=[f'feature_{i}' for i in range(features_to_analyse.shape[1])])\n",
    "adata.uns['iroot'] = np.flatnonzero(adata.obs['cell_stage'] == 'Interphase')[0]\n",
    "neighbors = sc.pp.neighbors(adata, use_rep='X')\n",
    "sc.tl.diffmap(adata, n_comps=10)\n",
    "neighbors = sc.pp.neighbors(adata, use_rep='X', copy=True)\n",
    "sc.tl.dpt(adata)\n",
    "pseudo_time = adata.obs['dpt_pseudotime'].values\n",
    "\n",
    "transition_matrix = neighbors.obsp['connectivities']\n",
    "eig_val, eig_vec = eigs(transition_matrix, k=10)\n",
    "\n",
    "cell_stage_groups = sorted_df.reset_index().groupby(['cell_stage']).groups\n",
    "pseudo_time_divided_by_cell_stages = [(pseudo_time)[cell_stage_groups[k]] for k in sorted(cell_stage_groups.keys())]\n",
    "no_inf_pseudo_time = np.where(pseudo_time == np.inf, np.nan, pseudo_time)\n",
    "mean_pseudotime = [np.nanmean(no_inf_pseudo_time[cell_stage_groups[k]]) for k in sorted(cell_stage_groups.keys())]\n",
    "std_pseudotime = [np.nanstd(no_inf_pseudo_time[cell_stage_groups[k]]) for k in sorted(cell_stage_groups.keys())]\n",
    "\n",
    "cell_stage_groups = sorted_df.groupby('cell_stage').groups\n",
    "for i in range(7):\n",
    "    for j in range(i + 1, 7):\n",
    "        plt.figure(figsize=(2.5, 2.5), dpi=300)\n",
    "        for ind, key in enumerate(phases):\n",
    "            indices = cell_stage_groups[key]\n",
    "            plt.scatter(adata.obsm['X_diffmap'][indices,i],\n",
    "                        adata.obsm['X_diffmap'][indices,j], \n",
    "                        s=0.1,\n",
    "                        color=cmap(ind / len(phases)))\n",
    "            plt.xlabel(f'DC {i}')\n",
    "            plt.ylabel(f'DC {j}')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        plt.savefig(f'results/WTC11/WTC11_pseudotime_{i}_{j}.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d4afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_averaged_features, cell_columns = get_averaged_features(sorted_df, torch.Tensor(reduced_features), ['cell_stage'], sort=True)\n",
    "\n",
    "reduced_averaged_features = 1 - squareform(pdist(scaled_averaged_features, metric='cosine'))\n",
    "plt.figure()\n",
    "ground_truth_Z = linkage(reduced_averaged_features)\n",
    "dn = dendrogram(ground_truth_Z, labels = cell_columns)\n",
    "reduced_averaged_features = reduced_averaged_features[dn['leaves'], :][:, dn['leaves']]\n",
    "\n",
    "cell_columns = dn['ivl']\n",
    "plt.figure()\n",
    "plt.figure(figsize=(2.5,2.5), dpi=300)\n",
    "plt.imshow(reduced_averaged_features, cmap='Blues')\n",
    "plt.xticks([])\n",
    "plt.yticks(range(len(cell_columns)), cell_columns)\n",
    "print('')\n",
    "plt.savefig('results/WTC11/WTC11_Cell_stage_similarity.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb0b61c",
   "metadata": {},
   "source": [
    "### Analysing key descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e74c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from skimage import io\n",
    "from typing import Union, List, Tuple\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from utils.augmentations import Single_cell_Resize, Single_cell_centered, self_normalize\n",
    "import utils.vision_transformer as vits\n",
    "from utils.extractor import ViTExtractor\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "import faiss\n",
    "\n",
    "class FaissKNeighbors:\n",
    "    def __init__(self, k=5):\n",
    "        self.index = None\n",
    "        self.y = None\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.index = faiss.IndexFlatL2(X.shape[1])\n",
    "        self.index.add(X.astype(np.float32))\n",
    "        self.y = y\n",
    "\n",
    "    def predict_group(self, X):\n",
    "        distances, indices = self.index.search(X.astype(np.float32), k=self.k)\n",
    "        votes = self.y[indices]\n",
    "        incorrect_indices = np.where(np.ptp(votes, axis=1) > 0)\n",
    "        zero_indices = np.where(votes[:,0] == 0)[0]\n",
    "        one_indices = np.where(votes[:,0] == 1)[0]\n",
    "        result = np.zeros(len(votes))\n",
    "        result[one_indices] = 1\n",
    "        result[zero_indices] = 0\n",
    "        result[incorrect_indices] = np.nan\n",
    "        return result\n",
    "    \n",
    "    def predict_cell(self, X):\n",
    "        distances, indices = self.index.search(X.astype(np.float32), k=self.k)\n",
    "        votes = self.y[indices]\n",
    "        correct_cell = np.max(((votes[:, 1:] - votes[:,[0]]) == 0) == True, axis=1)\n",
    "        return correct_cell\n",
    "\n",
    "def preprocess(\n",
    "    image_path: Union[str, Path],\n",
    "    load_size: Union[int, Tuple[int, int]] = None,\n",
    ") -> Tuple[torch.Tensor, Image.Image]:\n",
    "    img = io.imread(image_path).transpose(1,2,0).astype(float)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    pil_image = img\n",
    "    if load_size is not None:\n",
    "        pil_image = transforms.Resize(\n",
    "            load_size, interpolation=transforms.InterpolationMode.LANCZOS\n",
    "        )(pil_image.astype(float))\n",
    "    prep = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            self_normalize(),\n",
    "        ]\n",
    "    )\n",
    "    prep_img = prep(pil_image[:,:,[1,2,3]])[None, ...]\n",
    "    return prep_img, pil_image\n",
    "\n",
    "model = vits.__dict__['vit_base'](\n",
    "    img_size=[224],\n",
    "    patch_size=8,\n",
    "    drop_path_rate=0.1,  # stochastic depth\n",
    "    in_chans=3,\n",
    ")\n",
    "state_dict = torch.load('WTC11_data/model_3_channels_checkpoint.pth')\n",
    "teacher = state_dict\n",
    "if \"teacher\" in state_dict.keys():\n",
    "    teacher = state_dict[\"teacher\"]\n",
    "teacher = {k.replace(\"module.\", \"\"): v for k, v in teacher.items()}\n",
    "teacher = {k.replace(\"backbone.\", \"\"): v for k, v in teacher.items()}\n",
    "model.load_state_dict(teacher, strict=False)\n",
    "\n",
    "extractor = ViTExtractor(\n",
    "    model_type='dino_vits8',\n",
    "    model=model,\n",
    "    stride=4,\n",
    "    device='cuda',\n",
    "    load_size=224,\n",
    ")\n",
    "\n",
    "df = pd.read_csv('WTC11_data/normalized_cell_df.csv')\n",
    "condition_1 = df[df.cell_stage.isin(['M0']) & df.Structure.isin(['mitochondria'])].sample(frac=1)\n",
    "condition_2 = df[df.cell_stage.isin(['M4M5']) & df.Structure.isin(['mitochondria'])].sample(frac=1)\n",
    "\n",
    "num_cells_per_group = 50\n",
    "small_df = pd.concat((\n",
    "    condition_1.iloc[:num_cells_per_group],\n",
    "    condition_2.iloc[:num_cells_per_group],\n",
    "          ))\n",
    "\n",
    "images_paths = small_df.file.values\n",
    "all_descriptors = []\n",
    "all_descriptors_clean = []\n",
    "all_images = []\n",
    "all_features = []\n",
    "for path in tqdm(images_paths):\n",
    "    image_batch, image_pil = preprocess(path)  \n",
    "    image_pil = io.imread(path.replace('normalized_cell_data','cell_data'))\n",
    "    descs = extractor.extract_descriptors(image_batch.to('cuda')).detach().cpu().numpy()[0,0,:,:]\n",
    "    cell_mask = (image_pil[5,:,:]).astype(bool)\n",
    "    cell_mask = (cv2.resize(cell_mask.astype(float), dsize=(92, 58), interpolation=cv2.INTER_CUBIC) > 0.5)    \n",
    "    descs = extractor.extract_descriptors(image_batch.to('cuda')).detach().cpu().numpy()[0,0,:,:]\n",
    "    all_descriptors_clean.append(np.copy(descs))\n",
    "    descs[cell_mask.flatten() == False,:] = 0\n",
    "    all_descriptors.append(descs)\n",
    "    all_images.append(np.array(image_pil))\n",
    "    all_features.append(model(image_batch.to('cuda')).detach().cpu().numpy())\n",
    "all_descriptors = np.stack(all_descriptors)\n",
    "all_descriptors_clean = np.stack(all_descriptors_clean)\n",
    "all_images = np.stack(all_images)\n",
    "\n",
    "\n",
    "group_IDs = np.array([[0] * 5336 for i in range(num_cells_per_group)] + [[1] * 5336 for i in range(num_cells_per_group)]).flatten()\n",
    "cell_IDs = np.array([[[j] * 5336] for j in range(num_cells_per_group * 2)]).flatten()\n",
    "n_components = 10\n",
    "pca = PCA(n_components=n_components, whiten=True)\n",
    "pca_descs = pca.fit_transform(np.concatenate(all_descriptors))\n",
    "pca_descs_clean = pca.fit_transform(np.concatenate(all_descriptors_clean))\n",
    "individual_pca_descs = pca_descs.reshape(all_descriptors.shape[0], all_descriptors.shape[1], n_components)\n",
    "individual_pca_descs_clean = pca_descs_clean.reshape(all_descriptors.shape[0], all_descriptors.shape[1], n_components)\n",
    "\n",
    "group_fknn = FaissKNeighbors(k=5)\n",
    "queries = pca_descs[:,:4]\n",
    "group_fknn.fit(queries, group_IDs)\n",
    "predictions = group_fknn.predict_group(queries)\n",
    "robust_group_descriptor_indices_0 = np.where(predictions == 0)[0]\n",
    "robust_group_descriptor_indices_1 = np.where(predictions == 1)[0]\n",
    "\n",
    "cell_fknn = FaissKNeighbors(k=2)\n",
    "cell_fknn.fit(queries, cell_IDs)\n",
    "predictions = cell_fknn.predict_cell(queries)\n",
    "robust_cell_descriptor_indices = np.where(predictions)[0]\n",
    "\n",
    "robust_group_descriptor_indices_0 = np.array(list(set(robust_group_descriptor_indices_0).difference(robust_cell_descriptor_indices)))\n",
    "robust_group_descriptor_indices_1 = np.array(list(set(robust_group_descriptor_indices_1).difference(robust_cell_descriptor_indices)))\n",
    "robust_group_descriptor_indices_0 = robust_group_descriptor_indices_0[:len(robust_group_descriptor_indices_1)]\n",
    "robust_group_descriptor_indices_1 = robust_group_descriptor_indices_1[:len(robust_group_descriptor_indices_0)]\n",
    "\n",
    "group_1_inds = list(range(num_cells_per_group))\n",
    "group_2_inds = list(range(len(individual_pca_descs) - num_cells_per_group,len(individual_pca_descs),1))\n",
    "cytosol_IOUs = []\n",
    "nucleus_IOUs = []\n",
    "individual_pca_descs = pca_descs.reshape(all_descriptors.shape[0], all_descriptors.shape[1], n_components)\n",
    "informative_descriptors = np.array([np.unravel_index(ind, all_descriptors.shape[:2]) for ind in sorted(robust_group_descriptor_indices_0)[:len(robust_group_descriptor_indices_1)] + sorted(robust_group_descriptor_indices_1)[:len(robust_group_descriptor_indices_0)]])\n",
    "\n",
    "for ind in range(len(individual_pca_descs)):\n",
    "    informative_inds = informative_descriptors[np.where(informative_descriptors[:,0] == ind)[0], 1]\n",
    "    mask = np.zeros((58, 92))\n",
    "    masked_indices = np.array([np.unravel_index(ind, mask.shape) for ind in sorted(informative_inds)])\n",
    "    mask.flat[informative_inds] = 1\n",
    "    mask = (cv2.resize(mask, dsize=(374, 238), interpolation=cv2.INTER_CUBIC) > 0.5)\n",
    "    \n",
    "    image_pil = all_images[ind]\n",
    "    nucleus = image_pil[4,:,:].astype(bool)\n",
    "    cytosol = (image_pil[5,:,:] - image_pil[4,:,:]).astype(bool)\n",
    "    mask = mask * image_pil[5,:,:]\n",
    "\n",
    "    overlap = nucleus * mask # Logical AND\n",
    "    union = nucleus + mask # Logical OR\n",
    "    nucleus_IOU = overlap.sum()/float(union.sum())\n",
    "    nucleus_IOUs.append(nucleus_IOU)\n",
    "    \n",
    "    overlap = cytosol * mask # Logical AND\n",
    "    union = cytosol + mask # Logical OR\n",
    "    cytosol_IOU = overlap.sum()/float(union.sum())\n",
    "    cytosol_IOUs.append(cytosol_IOU)\n",
    "group_1_cytosol_IOUs = np.array(cytosol_IOUs)[group_1_inds]\n",
    "group_1_nucleus_IOUs = np.array(nucleus_IOUs)[group_1_inds]\n",
    "\n",
    "group_2_cytosol_IOUs = np.array(cytosol_IOUs)[group_2_inds]\n",
    "group_2_nucleus_IOUs = np.array(nucleus_IOUs)[group_2_inds]\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(2.5,2.5))\n",
    "plt.bar(x=[0], \n",
    "        bottom=0,\n",
    "        height=[\n",
    "            np.mean(group_1_nucleus_IOUs),    \n",
    "        ],\n",
    "        color='red',\n",
    "       width=0.5)\n",
    "plt.bar(x=[0.5], \n",
    "        bottom=0,\n",
    "        height=[\n",
    "            np.mean(group_1_cytosol_IOUs),    \n",
    "        ],\n",
    "        color='blue',\n",
    "       width=0.5)\n",
    "\n",
    "plt.bar(x=[1.5], \n",
    "        bottom=0,\n",
    "        height=[\n",
    "            np.mean(group_2_nucleus_IOUs),    \n",
    "        ],\n",
    "        label='Nucleus',\n",
    "        color='red',\n",
    "       width=0.5)\n",
    "plt.bar(x=[2], \n",
    "        bottom=0,\n",
    "        height=[\n",
    "            np.mean(group_2_cytosol_IOUs),    \n",
    "        ],\n",
    "        color='blue',\n",
    "        label='Cytoplasm',\n",
    "       width=0.5)\n",
    "\n",
    "plt.xticks([0.25, 1.75], ['Interphase', 'prometaphase/\\nmetaphase'], rotation=45)\n",
    "plt.ylabel('IoU of indicative tokens')\n",
    "plt.savefig('results/WTC11/WTC11_ratio.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346247a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import skimage\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "magenta_cmap = LinearSegmentedColormap.from_list('magentas', ['#000000','#ff14ff'], N=256)\n",
    "cyan_cmap = LinearSegmentedColormap.from_list('cyans', ['#000000','#00ffff'], N=256)\n",
    "white_cmap = LinearSegmentedColormap.from_list('whites', ['#7a7a7a','#ffffff'], N=256)\n",
    "\n",
    "individual_pca_descs = pca_descs.reshape(all_descriptors.shape[0], all_descriptors.shape[1], n_components)\n",
    "individual_pca_descs_clean = pca_descs_clean.reshape(all_descriptors_clean.shape[0], all_descriptors_clean.shape[1], n_components)\n",
    "informative_descriptors = np.array([np.unravel_index(ind, all_descriptors.shape[:2]) for ind in sorted(robust_group_descriptor_indices_0) + sorted(robust_group_descriptor_indices_1)])\n",
    "size = 3\n",
    "# inds = [0,1]\n",
    "# inds = [0,1,2,3]\n",
    "inds = [1,len(individual_pca_descs) - 1]\n",
    "# inds = [0,len(individual_pca_descs) - 4]\n",
    "# inds = [0,1,len(individual_pca_descs) - 2,len(individual_pca_descs) - 1]\n",
    "# inds = range(len(individual_pca_descs))\n",
    "fig, axes = plt.subplots(len(inds),3,figsize=(3 * size, len(inds) * size * 238 / 374))\n",
    "\n",
    "for axis_ind, (ind, desc, desc_clean) in enumerate(zip(inds, individual_pca_descs[inds], individual_pca_descs_clean[inds])):\n",
    "    informative_inds = informative_descriptors[np.where(informative_descriptors[:,0] == ind)[0], 1]\n",
    "    mask = np.zeros((58, 92))\n",
    "    masked_indices = np.array([np.unravel_index(ind, mask.shape) for ind in sorted(informative_inds)])\n",
    "    mask.flat[informative_inds] = 1\n",
    "    print(mask.mean())\n",
    "    \n",
    "    desc.reshape(58, 92, desc.shape[-1]).shape\n",
    "    desc = np.stack([cv2.resize(desc[:,c].reshape(58, 92), dsize=(374, 238), interpolation=cv2.INTER_CUBIC) for c in range(n_components)]).transpose(1,2,0)\n",
    "    desc_clean.reshape(58, 92, desc.shape[-1]).shape\n",
    "    desc_clean = np.stack([cv2.resize(desc_clean[:,c].reshape(58, 92), dsize=(374, 238), interpolation=cv2.INTER_CUBIC) for c in range(n_components)]).transpose(1,2,0)\n",
    "    mask = (cv2.resize(mask, dsize=(374, 238), interpolation=cv2.INTER_CUBIC) > 0.5)\n",
    "    \n",
    "    masks = []\n",
    "    for img_c in range(3):\n",
    "        masks.append((all_images[ind, :, :, img_c] > \n",
    "                       threshold_otsu(all_images.transpose(0,2,3,1)[ind, :, :, img_c].flatten()[all_images.transpose(0,2,3,1)[ind, :, :, img_c].flatten().nonzero()])).astype(int))\n",
    "    \n",
    "    new_desc = np.copy(desc)\n",
    "    new_desc -= new_desc.min(axis=(0,1))\n",
    "    new_desc /= new_desc.max(axis=(0,1))\n",
    "    new_desc_clean = np.copy(desc_clean)\n",
    "    new_desc_clean -= new_desc_clean.min(axis=(0,1))\n",
    "    new_desc_clean /= new_desc_clean.max(axis=(0,1))\n",
    "\n",
    "    axes[axis_ind][0].imshow(new_desc_clean[:,:,0])\n",
    "    axes[axis_ind][0].imshow(mask, alpha=mask.astype(float), cmap=magenta_cmap)\n",
    "    axes[axis_ind][0].axis('off')\n",
    "    \n",
    "    axes[axis_ind][1].imshow(new_desc_clean[:,:,[1,2,3]])\n",
    "#     axes[axis_ind][1].imshow(mask, alpha=mask.astype(float))\n",
    "    axes[axis_ind][1].axis('off')    \n",
    "    img = np.copy(all_images[ind])\n",
    "#     img -= img.min(axis=(0,1))\n",
    "#     img /= img.max(axis=(0,1))\n",
    "    aim = img\n",
    "    nucleus = skimage.exposure.rescale_intensity(aim[1,:,:], out_range=\"uint8\")\n",
    "    membrane = skimage.exposure.rescale_intensity(aim[2,:,:], out_range=\"uint8\")\n",
    "    protein = skimage.exposure.rescale_intensity(aim[3,:,:], out_range=\"uint8\")\n",
    "    nuc_mask = skimage.segmentation.find_boundaries(aim[4,:,:])*255\n",
    "    mem_mask = skimage.segmentation.find_boundaries(aim[5,:,:])*255\n",
    "    RGB = np.zeros((aim.shape[1], aim.shape[2], 3))\n",
    "    MAX = np.ones_like(RGB)*255\n",
    "    N1 = nuc_mask[:,:,np.newaxis] * np.asarray([[[0,1,1]]])\n",
    "    N2 = nucleus[:,:,np.newaxis] * np.asarray([[[0,1,1]]])\n",
    "    M1 = mem_mask[:,:,np.newaxis] * np.asarray([[[1,0,1]]])\n",
    "    M2 = membrane[:,:,np.newaxis] * np.asarray([[[1,0,1]]])\n",
    "    P1 = protein[:,:,np.newaxis] * np.asarray([[[1,1,1]]])\n",
    "    P2 = np.asarray(0.4*np.bitwise_or(N2, M2) + 0.6*P1, dtype=np.uint8)\n",
    "    RGB = np.bitwise_or(P2, np.bitwise_or(N1, M1))\n",
    "    axes[axis_ind][2].imshow(RGB)\n",
    "#     axes[axis_ind][2].imshow(mask, alpha=mask.astype(float), cmap=magenta_cmap)\n",
    "    axes[axis_ind][2].axis('off')\n",
    "\n",
    "\n",
    "channel_names = ['PC 1','PCs 2,3,4','DNA, Cell membrane, Structure']\n",
    "for c,name in enumerate(channel_names):\n",
    "    axes[0][c].set_title(name, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/WTC11/WTC11_attention_cells.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343632dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794380f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1d46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
