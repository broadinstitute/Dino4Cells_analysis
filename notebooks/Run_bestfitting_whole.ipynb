{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c72b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import io\n",
    "import onnxruntime as ort\n",
    "import onnx\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44751406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0a01d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_opcounter import calculate_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf5d46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = calculate_params(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adcbd2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9157346"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7004e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2b4c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load('densenet_model.onnx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01b134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx2torch import convert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7c27c60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Converter is not implemented (OperationDescription(domain='', operation_type='GlobalMaxPool', version=1))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch_model_1 \u001b[38;5;241m=\u001b[39m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/onnx2torch/converter.py:104\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(onnx_model_or_path, save_input_names, attach_onnx_mapping)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, onnx_node \u001b[38;5;129;01min\u001b[39;00m onnx_graph\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    103\u001b[0m     version \u001b[38;5;241m=\u001b[39m opset_import[onnx_node\u001b[38;5;241m.\u001b[39mdomain]\n\u001b[0;32m--> 104\u001b[0m     converter \u001b[38;5;241m=\u001b[39m \u001b[43mget_converter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     torch_module, onnx_mapping \u001b[38;5;241m=\u001b[39m converter(onnx_node, onnx_graph)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_onnx_mapping:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/onnx2torch/node_converters/registry.py:69\u001b[0m, in \u001b[0;36mget_converter\u001b[0;34m(operation_type, version, domain)\u001b[0m\n\u001b[1;32m     67\u001b[0m converter \u001b[38;5;241m=\u001b[39m _CONVERTER_REGISTRY\u001b[38;5;241m.\u001b[39mget(description, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m converter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConverter is not implemented (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m converter\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Converter is not implemented (OperationDescription(domain='', operation_type='GlobalMaxPool', version=1))"
     ]
    }
   ],
   "source": [
    "torch_model_1 = convert(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0210dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is valid!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    onnx.checker.check_model('densenet_model_batch.onnx')\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print(f\"The model is invalid: {e}\")\n",
    "else:\n",
    "    print(\"The model is valid!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d200e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load('densenet_model.onnx')\n",
    "model.graph.input[0].type.tensor_type.shape.dim[0].dim_param = 'batch_size'\n",
    "model.graph.input[0].type.tensor_type.shape.dim[0].ClearField('dim_value')\n",
    "onnx.save(model, 'densenet_model_batch.onnx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ad1a548",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "parameters",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m total_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m())\n\u001b[1;32m      2\u001b[0m learnable_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad)\n",
      "\u001b[0;31mAttributeError\u001b[0m: parameters"
     ]
    }
   ],
   "source": [
    "total_params = sum(p for p in model.parameters())\n",
    "learnable_params = sum(p for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf64dfce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__name__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: __name__"
     ]
    }
   ],
   "source": [
    "model.__srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98fb2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = ort.InferenceSession(\"densenet_model.onnx\", None, providers=[\"CUDAExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d169a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "606132a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m batch_size_per_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[1;32m     35\u001b[0m IDs \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scr/mdoron/Dino4Cells/models/FAIR_whole_image_all_channels/features.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m---> 37\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mProteinDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIDs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1536\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_trainset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrop_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_crop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_numpy\u001b[39m(tensor):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;28;01melse\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Dino4Cells/protein_dataset.py:92\u001b[0m, in \u001b[0;36mProteinDataset.__init__\u001b[0;34m(self, file_list, img_size, transform, return_label, is_trainset, in_channels, crop_size, random_crop, target_labels)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     81\u001b[0m     file_list,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m ):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# self.imlist = pandas_reader_binary_labels(file_list, target_labels)[60000:70000]\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimlist \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_reader_binary_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_trainset \u001b[38;5;241m=\u001b[39m is_trainset\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size \u001b[38;5;241m=\u001b[39m img_size\n",
      "File \u001b[0;32m~/Dino4Cells/protein_dataset.py:60\u001b[0m, in \u001b[0;36mpandas_reader_binary_labels\u001b[0;34m(flist, target_labels)\u001b[0m\n\u001b[1;32m     58\u001b[0m     files \u001b[38;5;241m=\u001b[39m flist\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflist\u001b[49m\u001b[43m)\u001b[49m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# files = pd.read_csv(flist)[[\"file\", \"ID\", \"cell_type\"] + target_labels]\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# target_matrix = files[target_labels].values.astype(int)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m file_names \u001b[38;5;241m=\u001b[39m files[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1750\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1749\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'list'>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "from utils import Multilabel_classifier\n",
    "import torch\n",
    "import vision_transformer as vits\n",
    "from file_dataset import ImageFileList, AutoBalancedFileList, default_loader, pandas_reader, pandas_reader_no_labels, pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "from yaml_tfms import tfms_from_config\n",
    "import numpy as np\n",
    "from label_dict import protein_to_num_full as protein_to_num\n",
    "from sklearn.metrics import f1_score\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import importlib\n",
    "import file_dataset\n",
    "from label_dict import protein_to_num_full\n",
    "importlib.reload(file_dataset)\n",
    "ImageFileList = file_dataset.ImageFileList\n",
    "pandas_reader_binary_labels = file_dataset.pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import Multilabel_classifier, simple_clf, expanding_clf, prototyping_clf, residual_clf, residual_add_clf\n",
    "import protein_dataset\n",
    "importlib.reload(protein_dataset)\n",
    "from protein_dataset import ProteinDataset \n",
    "\n",
    "batch_size_per_gpu = 512\n",
    "IDs = (torch.load('/scr/mdoron/Dino4Cells/models/FAIR_whole_image_all_channels/features.pth')[3])\n",
    "\n",
    "dataset = ProteinDataset(\n",
    "        IDs,\n",
    "        img_size=1536,\n",
    "        is_trainset=False,\n",
    "        return_label=False,\n",
    "        in_channels=4,\n",
    "        transform=None,\n",
    "        crop_size=1024,\n",
    "        random_crop=False,\n",
    "    )\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "IDs = []\n",
    "features = []\n",
    "predictions = []\n",
    "for ind, (img, ID) in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    ort_outs = ort_session.run(None, {'image': to_numpy(img[np.newaxis,:,:,:])})\n",
    "    IDs.append(ID)\n",
    "    predictions.append(ort_outs[0])\n",
    "    features.append(ort_outs[1])\n",
    "\n",
    "sigmoid_predictions = (torch.Tensor(predictions)).round().squeeze(1)[:, mapping]\n",
    "\n",
    "submissions = []\n",
    "for i in (sigmoid_predictions):\n",
    "    if len(i) == 0:\n",
    "        submissions.append('')\n",
    "    else:\n",
    "        submissions.append(' '.join([str(v) for v in np.where(i)[0]]))\n",
    "        \n",
    "# submission = pd.DataFrame(zip(dataset.img_ids, submissions), columns=['Id', 'Predicted'])\n",
    "# submission = submission.sort_values(by='Id')\n",
    "# submission.to_csv(f'bestfitting_submission.csv', index=False)\n",
    "# os.system('kaggle competitions submit -c human-protein-atlas-image-classification -f bestfitting_submission.csv -m bestfitting -q')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd67370",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = torch.zeros(len(dataset), 1024).float()\n",
    "all_proteins = torch.zeros(len(dataset), 28).int()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b77dc4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7f64e7afc6f0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_session.get_inputs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c53aba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/data/protein/test/images_1536\n",
      "/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/data/protein/train/external_v18_1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██                                                                                                                                                                 | 150/11702 [00:10<13:12, 14.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m all_proteins \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(dataset), \u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     69\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, ID \u001b[38;5;129;01min\u001b[39;00m tqdm(kaggle_data_loader):\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# for img, protein, cell, ID in tqdm(kaggle_data_loader):\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     img1 \u001b[38;5;241m=\u001b[39m img\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1315\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1315\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1317\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "from utils import Multilabel_classifier\n",
    "import torch\n",
    "import vision_transformer as vits\n",
    "from file_dataset import ImageFileList, AutoBalancedFileList, default_loader, pandas_reader, pandas_reader_no_labels, pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "from yaml_tfms import tfms_from_config\n",
    "import numpy as np\n",
    "from label_dict import protein_to_num_full as protein_to_num\n",
    "from sklearn.metrics import f1_score\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import importlib\n",
    "import file_dataset\n",
    "from label_dict import protein_to_num_full\n",
    "importlib.reload(file_dataset)\n",
    "ImageFileList = file_dataset.ImageFileList\n",
    "pandas_reader_binary_labels = file_dataset.pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import Multilabel_classifier, simple_clf, expanding_clf, prototyping_clf, residual_clf, residual_add_clf\n",
    "import protein_dataset\n",
    "importlib.reload(protein_dataset)\n",
    "from protein_dataset import ProteinDataset \n",
    "\n",
    "batch_size_per_gpu = 1\n",
    "\n",
    "dataset = ProteinDataset(\n",
    "        '/scr/mdoron/Dino4Cells/data/kaggle_whole_image_test_IDs.csv',\n",
    "        img_size=1536,\n",
    "        is_trainset=False,\n",
    "        return_label=False,\n",
    "        in_channels=4,\n",
    "        transform=None,\n",
    "        crop_size=1024,\n",
    "        random_crop=False,\n",
    "        target_labels=sorted(list(protein_to_num_full.keys()))\n",
    ")\n",
    "\n",
    "kaggle_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "#     sampler=train_sampler,\n",
    "    batch_size=batch_size_per_gpu,\n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "IDs = []\n",
    "features = []\n",
    "cell_lines = []\n",
    "proteins = []\n",
    "bad_IDs = []\n",
    "outputs = []\n",
    "all_features = torch.zeros(len(dataset), 1024).float()\n",
    "all_proteins = torch.zeros(len(dataset), 28).float()\n",
    "i = 0\n",
    "for img, ID in tqdm(kaggle_data_loader):\n",
    "# for img, protein, cell, ID in tqdm(kaggle_data_loader):\n",
    "    img1 = img\n",
    "    try:\n",
    "        ort_outs = ort_session.run(None, {'image': to_numpy(img)})\n",
    "        IDs.extend(ID)\n",
    "#         cell_lines.extend(cell)\n",
    "#         all_proteins[i,:] = protein[0]\n",
    "#         all_features[i,:] = torch.Tensor(ort_outs[1][0])\n",
    "        outputs.append(ort_outs[0])\n",
    "#         i += 1\n",
    "#         del ort_outs, img, protein, cell, ID\n",
    "    except:\n",
    "        bad_IDs.append(ID)\n",
    "\n",
    "# torch.save((all_features, all_proteins, cell_lines, IDs), '/scr/mdoron/Dino4Cells/models/bestfitting_whole/features.pth')        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab524e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((all_proteins, all_features, cell_lines, IDs), '/scr/mdoron/Dino4Cells/models/bestfitting_whole/features.pth')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cda54336",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (np.stack(outputs)[:,0,:] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5bec05ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = []\n",
    "for i in predictions:\n",
    "    if len(i) == 0:\n",
    "        submissions.append(\"\")\n",
    "    else:\n",
    "        submissions.append(\" \".join([str(v) for v in np.where(i)[0]]))\n",
    "\n",
    "submission = pd.DataFrame(zip(IDs, submissions), columns=[\"Id\", \"Predicted\"])\n",
    "submission = submission.sort_values(by=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cc64082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('/scr/mdoron/Dino4Cells/results/bestfitting_whole/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61036b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24daaff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls '/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/' -lctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa39e7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/data/protein/test/images_1536\n",
      "/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/data/protein/train/external_v18_1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                                                                      | 1/366 [00:03<22:25,  3.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m bad_IDs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     66\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, ID \u001b[38;5;129;01min\u001b[39;00m tqdm(kaggle_data_loader):\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# for img, protein, cell, ID in tqdm(kaggle_data_loader):\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         ort_outs \u001b[38;5;241m=\u001b[39m ort_session\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mNone\u001b[39;00m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: to_numpy(img)})\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1315\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1315\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1317\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from utils import Multilabel_classifier\n",
    "import torch\n",
    "import vision_transformer as vits\n",
    "from file_dataset import ImageFileList, AutoBalancedFileList, default_loader, pandas_reader, pandas_reader_no_labels, pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "from yaml_tfms import tfms_from_config\n",
    "import numpy as np\n",
    "from label_dict import protein_to_num_full as protein_to_num\n",
    "from sklearn.metrics import f1_score\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import importlib\n",
    "import file_dataset\n",
    "from label_dict import protein_to_num_full\n",
    "importlib.reload(file_dataset)\n",
    "ImageFileList = file_dataset.ImageFileList\n",
    "pandas_reader_binary_labels = file_dataset.pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import Multilabel_classifier, simple_clf, expanding_clf, prototyping_clf, residual_clf, residual_add_clf\n",
    "import protein_dataset\n",
    "importlib.reload(protein_dataset)\n",
    "from protein_dataset import ProteinDataset \n",
    "\n",
    "batch_size_per_gpu = 32\n",
    "\n",
    "dataset = ProteinDataset(\n",
    "        '/mnt/data0/mdoron/HPA_data/whole_images_large_test.csv',\n",
    "        img_size=1536,\n",
    "        is_trainset=True,\n",
    "        return_label=True,\n",
    "        in_channels=4,\n",
    "        transform=None,\n",
    "        crop_size=1024,\n",
    "        random_crop=False,\n",
    "        target_labels=sorted(list(protein_to_num_full.keys()))\n",
    ")\n",
    "\n",
    "kaggle_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "#     sampler=train_sampler,\n",
    "    batch_size=batch_size_per_gpu,\n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "IDs = []\n",
    "features = []\n",
    "cell_lines = []\n",
    "proteins = []\n",
    "bad_IDs = []\n",
    "outputs = []\n",
    "for img, ID in tqdm(kaggle_data_loader):\n",
    "# for img, protein, cell, ID in tqdm(kaggle_data_loader):\n",
    "    try:\n",
    "        ort_outs = ort_session.run(None, {'image': to_numpy(img)})\n",
    "        outputs.append(ort_outs)\n",
    "#         IDs.extend(ID)\n",
    "#         cell_lines.extend(cell)\n",
    "#         proteins.extend(protein)\n",
    "#         features.append(ort_outs[1])\n",
    "    except:\n",
    "        bad_IDs.append(ID)\n",
    "\n",
    "# torch.save((features, proteins, cell_lines, IDs), '/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/test_features.pth')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c856576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/data/protein/train/images_1536\n",
      "/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/data/protein/train/external_v18_1536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = ProteinDataset(\n",
    "        '/scr/mdoron/Dino4Cells/data/kaggle_whole_image_test_IDs.csv',\n",
    "        img_size=1536,\n",
    "        is_trainset=True,\n",
    "        return_label=False,\n",
    "        in_channels=4,\n",
    "        transform=None,\n",
    "        crop_size=1024,\n",
    "        random_crop=False,\n",
    "        target_labels=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8bb159e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 1024, 1024])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d96d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from utils import Multilabel_classifier\n",
    "import torch\n",
    "import vision_transformer as vits\n",
    "from file_dataset import ImageFileList, AutoBalancedFileList, default_loader, pandas_reader, pandas_reader_no_labels, pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "from yaml_tfms import tfms_from_config\n",
    "import numpy as np\n",
    "from label_dict import protein_to_num_full as protein_to_num\n",
    "from sklearn.metrics import f1_score\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import importlib\n",
    "import file_dataset\n",
    "from label_dict import protein_to_num_full\n",
    "importlib.reload(file_dataset)\n",
    "ImageFileList = file_dataset.ImageFileList\n",
    "pandas_reader_binary_labels = file_dataset.pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import Multilabel_classifier, simple_clf, expanding_clf, prototyping_clf, residual_clf, residual_add_clf\n",
    "\n",
    "config = 'configs/config_supervised_ViT.yaml'\n",
    "config = yaml.safe_load(open(config, 'r'))\n",
    "class transformation(object):\n",
    "    def __init__(self, config, isTrain):\n",
    "        self.isTrain = isTrain\n",
    "        self.config = config\n",
    "        self.global_transfo1, self.global_transfo2, self.local_transfo, self.testing_transfo = tfms_from_config(self.config)\n",
    "    def __call__(self, image):\n",
    "        train_crop = self.global_transfo1(image)\n",
    "        test_crop = self.testing_transfo(image)\n",
    "        if self.isTrain:\n",
    "            return train_crop\n",
    "        else:\n",
    "            return test_crop\n",
    "\n",
    "train_transform = transformation(config, isTrain=True)\n",
    "test_transform = transformation(config, isTrain=False)\n",
    "\n",
    "batch_size_per_gpu = 512\n",
    "dataset = ImageFileList('/mnt/data0/mdoron/HPA_data/kaggle_test.csv', \n",
    "                               transform=test_transform, \n",
    "                               loader = default_loader, \n",
    "                               flist_reader = pandas_reader_no_labels, \n",
    "                               root=config['model']['root'],\n",
    "                               with_labels=False,\n",
    "                               training=False,\n",
    "                               target_labels=None,\n",
    "                               balance=False)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size_per_gpu,\n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "IDs = []\n",
    "cell_lines = []\n",
    "features = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    for images, ID in tqdm(data_loader):\n",
    "        features.append(model(images.cuda()).detach().cpu())\n",
    "        IDs.extend(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984ba9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
