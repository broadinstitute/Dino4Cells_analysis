{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e563e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46dc88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOV_files = [str(f) for f in Path('/scr/mdoron/allen/FOV/fov_path///').glob('*.tiff') if os.path.getsize(f) > 0 if 'ome' not in str(f)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0b8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391e6cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4194"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FOV_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ed9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(FOV_files[2]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a26bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2cbd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     plt.figure(figsize=(20,10))\n",
    "#     plt.imshow(img[[32 - 14, 32, 32 + 14],:,:,i].transpose(1,2,0), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e436c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c293e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6361e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fnet.cli.predict import parse_model, load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56166634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_def = parse_model(path_model_dir)\n",
    "model = load_model(model_def[\"path\"], no_optim=True)\n",
    "model.to_gpu(args.gpu_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfad897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = torch.load(f\"cell_epoch_30_GEN.pth\") \n",
    "\n",
    "ignore_index = 0 \n",
    "gpuid=0\n",
    "n_classes= 5\n",
    "in_channels= 3\n",
    "padding= True\n",
    "depth= 6\n",
    "wf= 5 \n",
    "up_mode= 'upconv' \n",
    "batch_norm = False \n",
    "batch_size=1\n",
    "patch_size=256\n",
    "edge_weight = 1.1 \n",
    "phases = [\"train\",\"val\"] \n",
    "validation_phases= [\"val\"] \n",
    "\n",
    "# Specify if we should use a GPU (cuda) or only the CPU\n",
    "if(torch.cuda.is_available()):\n",
    "    print(torch.cuda.get_device_properties(gpuid))\n",
    "    torch.cuda.set_device(gpuid)\n",
    "    device = torch.device(f'cuda:{gpuid}')\n",
    "else:\n",
    "    device = torch.device(f'cpu')\n",
    "\n",
    "# Define the network\n",
    "Gen = UNet(n_classes=n_classes, in_channels=in_channels, padding=padding,depth=depth,wf=wf, up_mode=up_mode, batch_norm=batch_norm).to(device)\n",
    "print(f\"total params: \\t{sum([np.prod(p.size()) for p in Gen.parameters()])}\")\n",
    "Gen.load_state_dict(checkpoint['model_dict'])\n",
    "Gen.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863491ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_img = img[[32 - 14, 32, 32 + 14],:600,:600,0].transpose(1,2,0).astype(float)\n",
    "# subset_img = cv2.resize(subset_img, dsize=(1200,1200), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# Define empty arrays\n",
    "checkfull = {}\n",
    "a = {}\n",
    "b2 = {}\n",
    "gt2 = {}\n",
    "gt3 = {}\n",
    "ionorm = {}\n",
    "blank_bf = np.zeros((3,1024, 1024), dtype=np.float32)          \n",
    "blank_fl = np.zeros((5, 1024, 1024))#, dtype=np.uint32)\n",
    "\n",
    "X1 = cv2.resize(subset_img, dsize=(998,998), interpolation=cv2.INTER_CUBIC)\n",
    "X1 = np.swapaxes(X1,0,2)\n",
    "X1 = np.swapaxes(X1,1,2)\n",
    "X1 = np.expand_dims(X1, axis = 0)\n",
    "\n",
    "subset_img -= subset_img.min()\n",
    "subset_img /= subset_img.max()\n",
    "subset_img *= 255\n",
    "subset_img = subset_img.astype(int)\n",
    "\n",
    "for channel in range(3):\n",
    "    X1a = X1[:,channel,:,:]\n",
    "    mean, std = X1a.mean(), X1a.std()\n",
    "    b2[channel] = (X1a-mean)/std\n",
    "    b2[channel] = np.expand_dims(b2[channel],axis = 0)\n",
    "    b29 = b2[channel]\n",
    "    gtim69 = Image.fromarray(b29[0,0,:,:])\n",
    "    if channel>0:\n",
    "        ionorm = np.concatenate((ionorm,b2[channel]),axis = 0)\n",
    "    else:\n",
    "        ionorm = b2[0]\n",
    "X1 = np.swapaxes(ionorm,0,1)\n",
    "blank_bf[:,0:998,0:998] = X1[0,:,:,:]\n",
    "X = blank_bf # X is the 3 channel 998x998 normalised brightfield input\n",
    "\n",
    "# These two loops execute the stitching algorithm (each pixel is the median of four overlapping 256x256 tiles)\n",
    "countP = 0\n",
    "for x in range(7):\n",
    "    for y in range(7):\n",
    "        x_in = X[:,x*128:(256+x*128), y*128:(256+y*128)]\n",
    "        x_in = np.expand_dims(x_in,axis = 0)\n",
    "        x_in = torch.from_numpy(x_in)\n",
    "        prediction1 = Gen(x_in.to(device))\n",
    "        checkfull = prediction1[0,:,:,:]\n",
    "        zy = checkfull.detach().cpu().numpy()\n",
    "        blank_fl[:,x*128:(256+x*128), y*128:(256+y*128)] = zy\n",
    "        gt3[countP] = zy\n",
    "        countP += 1\n",
    "\n",
    "for channel in range(5): \n",
    "    countP = 0\n",
    "    for P in range(49):\n",
    "        a = gt3[P]\n",
    "        gt2[P] = a[channel,:,:]\n",
    "        if P<7:\n",
    "            pass\n",
    "        else:\n",
    "            if P % 7 == 0:\n",
    "                countP += 1\n",
    "            else:\n",
    "                ca = gt2[(P-8)] \n",
    "                cb = gt2[(P-7)]\n",
    "                cc = gt2[(P-1)]\n",
    "                cd = gt2[(P)]\n",
    "                blank_fl[channel,countP*128:(countP+1)*128,\n",
    "                              (P - countP*7)*128:(P+1-countP*7)*128] = np.median([ca[128:,128:],cb[128:,0:128],\n",
    "                              cc[0:128,128:],cd[0:128,0:128]],axis=0)\n",
    "\n",
    "\n",
    "    # Save the stitched predicted image                          \n",
    "    im = blank_fl[channel,0:998,0:998]\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "    axes[0].imshow(subset_img[:,:,1], cmap='Greys')        \n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Brightfield')\n",
    "    axes[1].imshow(im, cmap='Greys_r')    \n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('ER (predicted)')    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FOV_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(FOV_files[93]).astype(float)\n",
    "fig, axes = plt.subplots(2,2, figsize=(10 * 2,7 * 2))\n",
    "axes[0][0].imshow(img[32,:,:,0], cmap='Greys_r')\n",
    "axes[0][0].axis('off')\n",
    "axes[0][0].set_title('brightfield')\n",
    "axes[1][0].imshow(img[32,:,:,1], cmap='Greys_r')\n",
    "axes[1][0].axis('off')\n",
    "axes[1][0].set_title('Structure')\n",
    "axes[0][1].imshow(img[32,:,:,2], cmap='Greys_r')\n",
    "axes[0][1].axis('off')\n",
    "axes[0][1].set_title('Cell membrane')\n",
    "axes[1][1].imshow(img[32,:,:,3], cmap='Greys_r')\n",
    "axes[1][1].axis('off')\n",
    "axes[1][1].set_title('DNA')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb538a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb0cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
