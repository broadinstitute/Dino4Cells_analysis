{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c72b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import io\n",
    "import onnxruntime as ort\n",
    "import onnx\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2b4c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load('HPA_FOV_data/densenet_model.onnx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01b134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx2torch import convert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0210dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is valid!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    onnx.checker.check_model('HPA_FOV_data/densenet_model_batch.onnx')\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print(f\"The model is invalid: {e}\")\n",
    "else:\n",
    "    print(\"The model is valid!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98fb2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = ort.InferenceSession(\"HPA_FOV_data/densenet_model.onnx\", None, providers=[\"CUDAExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d169a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd67370",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = torch.zeros(len(dataset), 1024).float()\n",
    "all_proteins = torch.zeros(len(dataset), 28).int()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b77dc4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7f64e7afc6f0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_session.get_inputs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c53aba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/data/protein/test/images_1536\n",
      "/mnt/data0/mdoron/HPA_data/HPA-competition-solutions/bestfitting/data/protein/train/external_v18_1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–ˆ                                                                                                                                                                   | 75/11702 [00:13<33:51,  5.72it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m all_proteins \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(dataset), \u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     69\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, ID \u001b[38;5;129;01min\u001b[39;00m tqdm(kaggle_data_loader):\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# for img, protein, cell, ID in tqdm(kaggle_data_loader):\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     img1 \u001b[38;5;241m=\u001b[39m img\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "from utils import Multilabel_classifier\n",
    "import torch\n",
    "import vision_transformer as vits\n",
    "from file_dataset import ImageFileList, AutoBalancedFileList, default_loader, pandas_reader, pandas_reader_no_labels, pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "from yaml_tfms import tfms_from_config\n",
    "import numpy as np\n",
    "from label_dict import protein_to_num_full as protein_to_num\n",
    "from sklearn.metrics import f1_score\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import importlib\n",
    "import file_dataset\n",
    "from label_dict import protein_to_num_full\n",
    "importlib.reload(file_dataset)\n",
    "ImageFileList = file_dataset.ImageFileList\n",
    "pandas_reader_binary_labels = file_dataset.pandas_reader_binary_labels\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import Multilabel_classifier, simple_clf, expanding_clf, prototyping_clf, residual_clf, residual_add_clf\n",
    "import protein_dataset\n",
    "importlib.reload(protein_dataset)\n",
    "from protein_dataset import ProteinDataset \n",
    "\n",
    "batch_size_per_gpu = 1\n",
    "\n",
    "dataset = ProteinDataset(\n",
    "        '/scr/mdoron/Dino4Cells/data/kaggle_whole_image_test_IDs.csv',\n",
    "        img_size=1536,\n",
    "        is_trainset=False,\n",
    "        return_label=False,\n",
    "        in_channels=4,\n",
    "        transform=None,\n",
    "        crop_size=1024,\n",
    "        random_crop=False,\n",
    "        target_labels=sorted(list(protein_to_num_full.keys()))\n",
    ")\n",
    "\n",
    "kaggle_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "#     sampler=train_sampler,\n",
    "    batch_size=batch_size_per_gpu,\n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "IDs = []\n",
    "features = []\n",
    "cell_lines = []\n",
    "proteins = []\n",
    "bad_IDs = []\n",
    "outputs = []\n",
    "all_features = torch.zeros(len(dataset), 1024).float()\n",
    "all_proteins = torch.zeros(len(dataset), 28).float()\n",
    "i = 0\n",
    "for img, ID in tqdm(kaggle_data_loader):\n",
    "# for img, protein, cell, ID in tqdm(kaggle_data_loader):\n",
    "    img1 = img\n",
    "    try:\n",
    "        ort_outs = ort_session.run(None, {'image': to_numpy(img)})\n",
    "        IDs.extend(ID)\n",
    "        outputs.append(ort_outs[0])\n",
    "    except:\n",
    "        bad_IDs.append(ID)\n",
    "\n",
    "# torch.save((all_features, all_proteins, cell_lines, IDs), 'bestfitting_test_features.pth')        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
